# Aitri Evolution Backlog

## ðŸŸ¢ Ready for Implementation

_(ninguno pendiente)_

## ðŸŸ¡ In Progress

---

## ðŸ“‹ Backlog

> _Feedback de prueba real (2026-02-27) â€” proyecto existente, flujo UX/UI improvement_

### EVO-048 â€” Gate CTA explÃ­cito: ambigÃ¼edad en "siguiente paso"

**Feedback:** Al terminar un gate, el agente muestra `Siguiente paso cuando quieras: aitri approve --feature X` sin dejar claro si estÃ¡ preguntando permiso o informando. El usuario no sabe si debe escribir "sÃ­", copiar el comando, o esperar.

**Scope:**
- En el skill `aitri`: al presentar el siguiente gate, usar lenguaje explÃ­cito: "Â¿Ejecuto `aitri approve` ahora? Responde **sÃ­** para que lo corra, o cÃ³pialo para correrlo tÃº."
- Nunca dejar un comando flotando sin instrucciÃ³n de acciÃ³n

**Prioridad:** Alta â€” confunde el flujo en cada transiciÃ³n de gate.

---

### EVO-049 â€” `status` y `resume` siempre terminan con `â†’ Siguiente acciÃ³n`

**Feedback:** Correr `aitri status --feature X` mostrÃ³ un reporte completo pero no anunciÃ³ el siguiente paso. El usuario tuvo que preguntar "Â¿quÃ© sigue?" explÃ­citamente.

**Scope:**
- `status` y `resume` deben siempre cerrar con un bloque `â†’ Siguiente: <comando concreto + descripciÃ³n de una lÃ­nea>`
- Si el feature estÃ¡ cerrado/entregado, decirlo explÃ­citamente

**Prioridad:** Alta â€” el pipeline se siente estancado sin este cierre proactivo.

---

### EVO-050 â€” Persona visibility: mostrar quÃ© persona estÃ¡ contribuyendo

**Feedback:** El usuario sabe que existen Arquitecto, UX, Dev, etc. pero no los ve "trabajar". No hay seÃ±al visible de cuÃ¡ndo cada persona contribuye ni quÃ© decidiÃ³.

**Scope:**
- Al invocar un comando de pre-planning (`arch-design`, `ux-design`, `sec-review`, etc.), mostrar badge: `[Arquitecto] Evaluando stack y componentesâ€¦`
- Al terminar, mostrar resumen de 2-3 lÃ­neas de quÃ© decidiÃ³ esa persona
- En `resume --json`, incluir `lastPersonaContribution: { persona, command, summary }`

**Prioridad:** Alta â€” las personas son el diferenciador de Aitri; si no se ven, no existen.

---

### EVO-051 â€” UX output pobre: resultado no alineado al requerimiento

**Feedback:** El resultado de `ux-design` fue pobre. El usuario no vio dÃ³nde vive el artefacto UX, no hubo propuesta visible para validar alineaciÃ³n, y el contenido generado no estuvo a la altura del requerimiento real (mejora UX/UI de dashboard).

**Scope:**
- Mejorar el prompt de `ux-design` para que genere: flujo de usuario, wireframe textual (ASCII o descripciÃ³n), decisiones de diseÃ±o con justificaciÃ³n
- Al terminar, mostrar path del artefacto y un preview inline de 10-15 lÃ­neas del contenido
- Agregar gate de validaciÃ³n: "Â¿Esta propuesta UX refleja tu requerimiento? (sÃ­/ajustar)"
- Considerar separar `ux-design` en dos pasos: `ux-brief` (entender requerimiento) â†’ `ux-proposal` (propuesta concreta)

**Prioridad:** Alta â€” es el artefacto con mayor impacto en features de producto y el mÃ¡s dÃ©bil actualmente.

---

### EVO-052 â€” Stack movido a post-arch (draft solo pregunta override)

**Feedback:** La pregunta de stack aparece en `draft` como opcional antes de que el arquitecto haya revisado. El stack deberÃ­a ser consecuencia del diseÃ±o arquitectÃ³nico, no una pregunta inicial.

**Scope:**
- `draft`: remover la pregunta de stack del wizard (o convertirla en: "Â¿Tienes restricciÃ³n de stack? Si no, el arquitecto lo definirÃ¡.")
- `arch-design`: el arquitecto propone el stack como parte de su output
- `build`: leer stack desde `arch-decision.md` si existe, desde `aitri.config.json` como fallback

**Prioridad:** Media â€” afecta calidad de las decisiones tÃ©cnicas.

---

### EVO-053 â€” Formato de US explÃ­cito al generar

**Feedback:** Al generar User Stories no quedÃ³ claro si seguÃ­an el template Aitri (FR-01/AC-01.x) o uno ad-hoc. El usuario no tuvo referencia para validar.

**Scope:**
- Al generar spec/draft, mostrar al inicio: "Generando bajo el formato Aitri: `FR-XX` con criterios `AC-XX.x`"
- Si la spec generada tiene IDs, validarlos con `approve` antes de mostrar como "listo"

**Prioridad:** Baja â€” es cosmÃ©tico pero afecta confianza en el output.

---

### EVO-045 â€” Integration tests con LLM real

**MotivaciÃ³n:** Todo el test suite es smoke/unit. No hay ningÃºn test que ejecute un flujo completo con AI real (incluso un modelo rÃ¡pido/barato). Gaps que solo los tests de integraciÃ³n pueden detectar: cambios en prompt format que rompen el parsing, regresiones en la estructura del output de `discover`, `plan`, `spec-improve`.

**Scope:**
- `tests/integration/` â€” nuevos tests marcados `@slow` / requieren `ANTHROPIC_API_KEY`
- `npm run test:integration` â€” script separado que no corre en CI bÃ¡sico
- Cobertura mÃ­nima: `draft â†’ approve â†’ discover â†’ plan` con un feature real pequeÃ±o

**Prioridad:** Media â€” los smoke tests cubren la lÃ³gica de orquestaciÃ³n, los integration tests cubrirÃ­an el contrato con el LLM.

---

### EVO-046 â€” `resume --feature` cross-epic awareness

**MotivaciÃ³n:** `resume --json` incluye `activeEpic` pero `resume --feature X` no consulta quÃ© Ã©pica contiene el feature. Si hay 2 Ã©picas con features entrelazados, el contexto de progreso relativo (cuÃ¡ntas features del epic estÃ¡n done) no se puede computar en `resume` sin este fix.

**Scope:**
- En `runResumeCommand`: cuando `options.feature` estÃ¡ presente, buscar quÃ© Ã©pica lo contiene
- Usar `readEpicsSummaryFromDocsRoot` ya disponible en `epic.js`
- AÃ±adir `epicContext: { epicName, position, total, delivered }` al JSON output

**Prioridad:** Baja â€” `activeEpic` ya funciona para el caso comÃºn (feature en curso).

---

### EVO-047 â€” Reducir `draft.js` por debajo del hard limit

**MotivaciÃ³n:** `cli/commands/draft.js` tiene 384 lÃ­neas (hard: 350). Deuda tÃ©cnica acumulada.

**Scope:**
- Extraer validaciÃ³n de idea a helper `validateIdea(idea)` en `cli/lib/`
- Extraer construcciÃ³n del prompt a funciÃ³n pura `buildDraftPrompt(options)`
- Sin cambio de comportamiento ni interface

**Prioridad:** Baja â€” deuda tÃ©cnica, no urgente.

---

## ðŸ”´ Done

> Historial completo en `git log`. Release actual: **v1.2.2**

### EVO-044 â€” Stale context detection: warn cuando pre-planning artifacts son mÃ¡s nuevos que downstream

**MotivaciÃ³n:** Post-mortem de EVO-038/042: los artefactos de pre-planning (`.aitri/architecture-decision.md`, `security-review.md`, `dev-roadmap.md`, `ux-design.md`, `qa-plan.md`) se generan y se consumen por `plan` y `build`. Pero si el usuario regenera un artefacto de pre-planning DESPUÃ‰S de haber corrido `plan`, el plan queda obsoleto sin ningÃºn aviso.

**Scope:**
- `cli/lib/staleness.js` â€” nuevo utilitario con `checkStaleness(sourceFiles, downstreamFile)` y `warnIfStale({...})`
- `cli/commands/build.js` â€” inyectar staleness check vs `planFile` (arch-decision, sec-review, dev-roadmap)
- `cli/commands/discovery-plan-validate.js` â€” inyectar staleness check antes de regenerar plan (arch-decision, sec-review, ux-design, qa-plan)
- `tests/smoke/cli-smoke-staleness.test.mjs` â€” 4 tests: warn cuando stale, no warn cuando clean, no warn cuando artifacts son mÃ¡s viejos, plan re-run avisa cuando stale

**Resultado:** 4 tests nuevos, 257 totales green. Warning es informativo, no bloqueante. `--force` en plan siempre regenera independientemente de staleness.

---

### EVO-043 â€” Cleanup: eliminar `handoff` y limpiar deprecation list

**Feedback origen:**
El help text decÃ­a `Still work (deprecated): discover, validate, handoff, scaffold, implement, verify, policy`. DiagnÃ³stico honesto: `handoff` es el Ãºnico genuinamente removible (reemplazado por `resume`). `discover`, `verify`, `validate`, `policy`, `scaffold`, `implement` son pasos reales del pipeline con tests dedicados â€” el label era errÃ³neo.

**Scope:**

- `cli/index.js`: eliminado dispatch de `handoff` + imports de `runHandoffCommand`. `scaffold` e `implement` conservados sin mensaje DEPRECATION. Help text actualizado: "Pipeline helpers" en lugar de "deprecated".
- `cli/commands/runtime-flow.js`: `runResumeCommand` ahora pasa `options.feature` a `getStatusReportOrExit` (fix latente â€” `resume --feature X` retornaba feature vacÃ­o).
- Tests actualizados: `handoff json` â†’ `resume --json` en 4 archivos (e2e, validation, runtime-policy, regression). Bonus: test renombrado a "resume and go respect --feature".

**Estado:** Implementado â€” 253 tests verdes.

---

### EVO-041 â€” Ã‰picas: container de features con progreso agregado

**Feedback origen:**
La jerarquÃ­a `Feature â†’ FR â†’ US â†’ TC` no tiene estructura intermedia para agrupar features hacia un outcome de negocio. Sin Ã©picas: no hay progreso agregado, `resume` no puede navegar cross-feature, no existe vista filtrada.

**Scope implementado:**

1. **`aitri epic create --name <name> --features <f1,f2,...>`** â†’ `docs/epics/<name>.json` con `schemaVersion`, `features[]`, `progressSummary`
2. **`aitri epic status [--name <name>]`** â€” sin `--name`: lista todas las Ã©picas; con `--name`: tabla feature/state/nextStep + progreso
3. **`aitri resume --json`** â€” incluye `activeEpic` y `epicProgress` en el payload
4. **`aitri status --epic <name>`** â€” vista filtrada por epic (redirige a `epic status`)
5. Features sin epic: intactas, backward compatible

Nuevo mÃ³dulo: `cli/commands/epic.js` (189 lÃ­neas). Nuevos flags globales: `--name`, `--features`, `--epic`. Tests: `tests/smoke/cli-smoke-epic.test.mjs` (14 tests).

**Estado:** Implementado â€” 131 smoke + 122 regression = 253 tests verdes.

---

### EVO-042 â€” Semantic context injection tests

**Feedback origen:**
Tests validan mecÃ¡nica (exit codes, archivos creados) pero no semÃ¡ntica: Â¿el output realmente usa el contexto disponible? Un pipeline que ignora `architecture-decision.md` en sus briefs pasarÃ­a todos los tests existentes sin objeciÃ³n.

**Scope:**

- `tests/smoke/cli-smoke-semantic-context.test.mjs` (nuevo) â€” 2 tests estructurales, sin LLM:
  - `build injects architecture-decision context into implementation briefs` â€” crea `.aitri/architecture-decision.md` con marcador Ãºnico, corre `aitri build`, verifica que el brief `US-*.md` contiene el marcador
  - `build omits architecture context when .aitri/architecture-decision.md is absent` â€” sin artefacto, verifica que el brief NO contiene la secciÃ³n de contexto
- `tests/smoke/cli-smoke-preplanning.test.mjs` â€” 3 tests nuevos de EVO-039 `--force` guard:
  - `discover-idea non-interactive fails with --force hint when artifact exists`
  - `discover-idea --force bypasses existing artifact guard`
  - `dev-roadmap non-interactive fails with --force hint when artifact exists`

**Por quÃ© solo `build`:** Es el Ãºnico comando del pipeline que inyecta contexto pre-planning sin invocar LLM â€” el marcador se escribe al archivo directamente. Los otros comandos que inyectan contexto (draft, plan) requieren LLM para producir su output, lo que hace inviable la aserciÃ³n sin mock.

**Estado:** Implementado â€” 240 tests verdes.

---

### EVO-040 â€” `aitri approve` semantic gate: spec vs architecture

**Feedback origen:**
`aitri approve` valida estructura del spec (secciones presentes, FRs formateados, ACs numerados) pero no verifica si el spec es coherente con `architecture-decision.md`. Un spec que contradice la arquitectura aprobada pasa el gate sin alerta. El audit lo detecta retroactivamente â€” post-daÃ±o.

**Scope:**

- Si existe `.aitri/architecture-decision.md`: agregar Layer 2 semÃ¡ntico al `approve` gate
- Invocar `architect.md` persona con: spec completo + architecture-decision
- Persona evalÃºa: Â¿El spec contradice alguna decisiÃ³n arquitectÃ³nica? Â¿Hay tecnologÃ­as no previstas? Â¿Hay gaps de seguridad evidentes?
- Output: `ARCH_CONCERN: <descripciÃ³n>` lines (igual que `FINDING:` en audit)
- Si hay concerns: mostrarlos y pedir confirmaciÃ³n antes de aprobar (`Proceed anyway? (y/n)`)
- Con `--yes`: concerns se muestran pero no bloquean (CI-friendly)
- Sin AI config: el gate semÃ¡ntico se omite silenciosamente (no rompe proyectos sin AI)

**Estado:** Implementado â€” 234 tests verdes.

---

### EVO-039 â€” Resume pre-planning awareness + `--force` para pre-planning

**Feedback origen:**
Post-mortem de EVO-037/038: `aitri resume json` no detecta si el pre-planning existe. En un proyecto nuevo devuelve `recommendedCommand: "aitri draft"` aunque `.aitri/discovery.md` no exista. Un agente que siga ciegamente `resume` omite todo el pre-planning. Segundo gap: no hay forma de regenerar un artefacto de pre-planning sin borrar el archivo manualmente.

**Scope:**

1. **`aitri resume`** â€” detectar estado de pre-planning:
   - Si ningÃºn artefacto `.aitri/*.md` existe (excepto `DEV_STATE.md`): `recommendedCommand: "aitri discover-idea"`, nuevo campo `prePlanningStatus: "not-started"`
   - Si pre-planning parcial (algunos artefactos existen): `prePlanningStatus: "in-progress"`, `recommendedCommand` apunta al siguiente en secuencia
   - Si pre-planning completo (`dev-roadmap.md` existe): `prePlanningStatus: "complete"`, comportamiento actual

2. **`--force` en los 7 comandos de pre-planning** â€” permite sobreescribir el artefacto existente sin borrar el archivo manualmente. Sin `--force`, si el artefacto ya existe, el comando pregunta si regenerar (interactivo) o falla limpio (no-interactivo).

**Estado:** Implementado â€” 234 tests verdes.

---

### EVO-038 â€” Cerrar gaps de integraciÃ³n: pre-planning alimenta el pipeline real

**Feedback origen:**
Post-mortem de EVO-037: los artefactos de pre-planning (`.aitri/dev-roadmap.md`, `architecture-decision.md`, `security-review.md`, `qa-plan.md`) se generan correctamente pero **ningÃºn comando del pipeline los consume**. El gap es entre artefactos producidos y artefactos usados.

**Gaps identificados (claims vs. realidad):**

| Gap | Impacto | Comando afectado |
|-----|---------|-----------------|
| `aitri draft` no lee `.aitri/dev-roadmap.md` | Alto â€” el spec se escribe sin la guÃ­a del Lead Developer | `draft.js` |
| `aitri plan` ignora `architecture-decision.md`, `security-review.md`, `qa-plan.md` | Alto â€” el backlog y tests se generan sin contexto arquitectÃ³nico ni de seguridad | `discovery-plan-validate.js` |
| `aitri build` no lee `architecture-decision.md` | Medio â€” scaffolding sin guÃ­a arquitectÃ³nica | `build.js` |
| `aitri approve` no valida consistencia spec vs architecture | Medio â€” gate estructural pero no semÃ¡ntico | `approve.js` |
| No hay gate UX antes del cÃ³digo | Medio â€” solo se verifica retroactivamente en audit | â€” |
| Las personas no se re-invocan cuando el contexto cambia | Bajo â€” depende del agente | SKILL.md |

**Causa raÃ­z documentada:**
Aitri creciÃ³ como herramienta de guardarraÃ­les estructurales (gates, validaciÃ³n de formato). El valor semÃ¡ntico â€” que el conocimiento fluya entre etapas â€” se asumiÃ³ implÃ­cito. Los tests validan mecÃ¡nica (exit codes, archivos creados) pero no semÃ¡ntica (Â¿el output usa el contexto disponible?).

**Principio correctivo adoptado:**
> Para cada artefacto que Aitri produce, debe existir al menos un comando posterior que lo consume.

**Scope implementado:**
- `aitri draft` â€” inyecta `.aitri/dev-roadmap.md` como secciÃ³n "Pre-Planning Context" en el spec generado
- `aitri plan` â€” inyecta `architecture-decision.md`, `security-review.md`, `ux-design.md` en las secciones correspondientes del plan doc; inyecta `qa-plan.md` en el tests file
- `aitri build` â€” inyecta `architecture-decision.md` y `security-review.md` como secciones adicionales en cada implementation brief
- `docs/architecture.md` â€” reescrito para reflejar el pipeline completo con personas activas, artifact topology actualizada, agent integration contract actualizado

**Estado:** Implementado â€” 234 tests verdes. Docs actualizados: `docs/architecture.md`, `docs/guides/GETTING_STARTED.md`, `docs/guides/AGENT_INTEGRATION_GUIDE.md`, `adapters/claude/SKILL.md`.

---

### EVO-037 â€” Persona-Driven SDLC: activar personas como cerebros del pipeline

**Feedback origen:**
Las 7 personas (`core/personas/*.md`) son documentos de referencia que ningÃºn comando LLM invoca. Los comandos actuales usan prompts inline genÃ©ricos o ningÃºn system prompt. El agente LLM opera sin lente de rol â€” genera UX sin pasar por el Experience Designer, genera cÃ³digo sin el Lead Developer, genera tests sin el Quality Engineer.

**Objetivo:**
Que cada etapa del SDLC sea ejecutada **por** su persona correspondiente. La persona se carga como system prompt desde su archivo `.md` y se pasa a `callAI()`. AsÃ­ el pipeline tiene cerebros especializados en cada paso, no un LLM genÃ©rico.

**Scope:**

1. **`cli/persona-loader.js`** (nuevo) â€” utilitario que lee `core/personas/<name>.md`, strips `## Invocation Policy`, retorna system prompt listo para `callAI`

2. **7 nuevos comandos pre-planning** (nivel proyecto, no feature):
   - `aitri discover-idea` â†’ Discovery Facilitator â†’ `.aitri/discovery.md`
   - `aitri product-spec` â†’ Product Manager â†’ `.aitri/product-spec.md`
   - `aitri ux-design` â†’ Experience Designer â†’ `.aitri/ux-design.md`
   - `aitri arch-design` â†’ System Architect â†’ `.aitri/architecture-decision.md`
   - `aitri sec-review` â†’ Security Champion â†’ `.aitri/security-review.md`
   - `aitri qa-plan` â†’ Quality Engineer â†’ `.aitri/qa-plan.md`
   - `aitri dev-roadmap` â†’ Lead Developer â†’ `.aitri/dev-roadmap.md`

3. **Refactors de comandos existentes** (sin breaking changes):
   - `spec-improve` â†’ usa `architect.md` en lugar de prompt inline
   - `testgen` â†’ agrega `qa.md` como system prompt
   - `contractgen` â†’ agrega `developer.md` como system prompt
   - `audit` layer 4 â†’ usa `architect.md` + `security.md` + `developer.md` + `ux-ui.md` (condicional)

**Pipeline resultante:**

```
Pre-planning (proyecto, 1 sola vez)
  discover-idea â†’ product-spec â†’ ux-design â†’ arch-design
  â†’ sec-review â†’ qa-plan â†’ dev-roadmap

Pre-Go (por feature)
  draft â†’ spec-improve[architect] â†’ approve[architect gate] â†’ go

Post-Go (factory)
  build â†’ testgen[qa] â†’ contractgen[developer] â†’ prove â†’ deliver

Post-delivery
  audit[architect + security + developer + ux-ui]
```

**Estado:** Implementado â€” commits `6cebaee`, `e046663`. Audit extendido a 4 personas (architect + security + developer + ux-ui condicional).

---
